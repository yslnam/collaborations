{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from random import seed\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.graphviz.org/pdf/dotguide.pdf\n",
    "https://victorzhou.com/blog/gini-impurity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions Section\n",
    "\n",
    "def pd_read_downsample(filename, per):\n",
    "    n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "    s = round(n*per)\n",
    "    skip = sorted(sample(range(1,n+1), n-s)) #the 0-indexed header will not be included in the skip list\n",
    "    df = pd.read_csv(filename, parse_dates = [], skiprows=skip)\n",
    "    return df\n",
    "    #unclear if creating a downsampled csv file would be useful here or to just retain the\n",
    "    #downsampled dataframe object\n",
    "    df.to_csv(downsampled_filename)\n",
    "    \n",
    "#helper function to print columns with missing and the percentage missingness:\n",
    "def colpercent(df):\n",
    "    print(\"Total NaN in Dataframe: \" , df.isnull().sum().sum())\n",
    "    print(\"Percent Missingness in Dataframe: \", 100*df.isnull().sum().sum()/(len(df.index)*len(df.columns)))\n",
    "    print('-'*55)\n",
    "    percentnulldf = df.isnull().sum()/(df.isnull().sum()+df.notna().sum())\n",
    "    print(\"Percent Missingness by Columns:\")\n",
    "    print(100*percentnulldf[percentnulldf>0].sort_values(ascending=False))\n",
    "    \n",
    "#printout to help view levels within features with missingness\n",
    "def colpercount(df):\n",
    "    percentnulldf = df.isnull().sum()/(df.isnull().sum()+df.notna().sum())\n",
    "    percent_ordered_df=percentnulldf[percentnulldf>0].sort_values(ascending=False)\n",
    "    for i in range(len(percent_ordered_df)):\n",
    "        print(percent_ordered_df.index[i])\n",
    "        print('-'*15)\n",
    "        print(df[percent_ordered_df.index[i]].value_counts())\n",
    "        print('-'*55)\n",
    "\n",
    "#helper function to print out percentage of zeroes by column\n",
    "def zeroper(df, value):\n",
    "    l=[]\n",
    "    columns=[]\n",
    "    for i in range(len(df.columns)):\n",
    "        if 0 in df[df.columns[i]].value_counts():\n",
    "            if 100*df[df.columns[i]].value_counts().loc[0]/len(df[df.columns[i]])>value:\n",
    "                l.append((df.columns[i], 100*df[df.columns[i]].value_counts().loc[0]/len(df[df.columns[i]])))\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    print(len(l))    \n",
    "    print('-'*55)\n",
    "    for j in range(len(l)):\n",
    "        columns.append(l[j][0])\n",
    "        print('Percent of zeroes: ', l[j])\n",
    "        print('-'*55)\n",
    "    print(columns)\n",
    "    return columns\n",
    "    \n",
    "#helper functions to characterize missingness by row and column\n",
    "def data_eval(df):\n",
    "    for i in range(len(df.columns)):\n",
    "        print('-'*50)\n",
    "        print('Column Name: ', df.columns[i])\n",
    "        if (df[df.columns[i]].dtypes == 'float64' or df[df.columns[i]].dtypes == 'int64') and df[df.columns[i]][df[df.columns[i]]<0].count()>0:\n",
    "            print('Number of negatives: ', df[df.columns[i]][df[df.columns[i]]<0].count())\n",
    "        if df[df.columns[i]][df[df.columns[i]]=='None'].count() > 0:\n",
    "            print('Number of None strings: ', df[df.columns[i]][df[df.columns[i]]=='None'].count())\n",
    "        if df[df.columns[i]][df[df.columns[i]]==''].count() > 0:\n",
    "            print('Number of empty strings: ', df[df.columns[i]][df[df.columns[i]]==''].count())\n",
    "        else:\n",
    "            print('Column ' + str(i) + ' has no negatives, empty strings or Nones')\n",
    "\n",
    "\n",
    "#generates list of percentage missingness by row\n",
    "def row_na_list(df, value):\n",
    "    l=[]\n",
    "    for i in range(len(df.index)) :\n",
    "        if df.iloc[i].isnull().sum() > value:\n",
    "            #print(i, df.iloc[i].isnull().sum())\n",
    "            l.append(i)\n",
    "    return l\n",
    "\n",
    "#helper function to retrieve row and column index labels for correlation matrix values\n",
    "#for greater than value when value>0 and less than value when value<0\n",
    "#and prints out the values that correspond to those indices\n",
    "def index_retrieve(df, value, measure):\n",
    "    poslist = list()\n",
    "    # Get bool dataframe with True at positions where the given value exists and filter out on-diagonal elements\n",
    "    if measure == 'spearman':\n",
    "        if value>0:\n",
    "            result = df.corr(method = measure)[df.corr(method = measure)!=1][df.corr(method = measure)>value].isna().isin([value])\n",
    "        if value<0:\n",
    "            result = df.corr(method = measure)[df.corr(method = measure)!=1][df.corr(method = measure)<value].isna().isin([value])\n",
    "        else:\n",
    "            pass\n",
    "    elif measure == 'pearson':\n",
    "        if value>0:\n",
    "            result = df.corr(method = measure)[df.corr(method = measure)!=1][df.corr(method = measure)>value].isna().isin([value])\n",
    "        elif value<0:\n",
    "            result = df.corr(method = measure)[df.corr(method = measure)!=1][df.corr(method = measure)<value].isna().isin([value])\n",
    "        else:\n",
    "            pass\n",
    "    # Get list of columns that contains the value\n",
    "    series = result.any()\n",
    "    columnNames = list(series[series == True].index)\n",
    "    # Iterate over list of columns and fetch the rows indexes where value exists\n",
    "    for col in columnNames:\n",
    "        rows = list(result[col][result[col] == True].index)\n",
    "        for row in rows:\n",
    "            poslist.append((row, col))\n",
    "    # Return a list of tuples indicating the positions of value in the dataframe\n",
    "    \n",
    "    if value > 0:\n",
    "        print('Number of correlations with value greater than ' + str(value) + ': ' + str(len(poslist)))\n",
    "    if value < 0:\n",
    "        print('Number of correlations with value less than ' + str(value) + ': ' + str(len(poslist)))\n",
    "    else:\n",
    "        pass\n",
    "    for i in range(len(poslist)):\n",
    "        print('-'*40)\n",
    "        print('index labels: ', poslist[i][0], poslist[i][1])\n",
    "        print('value at index: ', df.corr().loc[poslist[i]])\n",
    "    return poslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative using bash:\n",
    "\n",
    "For mac users who don't find shuf right away, please brew install first with brew install coreutils and then use the equivalence gshuf. This solution is much faster than calling random.\n",
    "\n",
    "This is not in Pandas, but it achieves the same result much faster through bash, while not reading the entire file into memory:\n",
    "\n",
    "shuf -n 100000 data/original.tsv > data/sample.tsv\n",
    "\n",
    "The shuf command will shuffle the input and the and the -n argument indicates how many lines we want in the output.\n",
    "\n",
    "Relevant question: https://unix.stackexchange.com/q/108581\n",
    "\n",
    "Benchmark on a 7M lines csv available here (2008):\n",
    "\n",
    "Top answer:\n",
    "\n",
    "def pd_read():\n",
    "    filename = \"2008.csv\"\n",
    "    n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "    s = 100000 #desired sample size\n",
    "    skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "    df = pandas.read_csv(filename, skiprows=skip)\n",
    "    df.to_csv(\"temp.csv\")\n",
    "\n",
    "Timing for pandas:\n",
    "\n",
    "%time pd_read()\n",
    "CPU times: user 18.4 s, sys: 448 ms, total: 18.9 s\n",
    "Wall time: 18.9 s\n",
    "\n",
    "While using shuf:\n",
    "\n",
    "time shuf -n 100000 2008.csv > temp.csv\n",
    "\n",
    "real    0m1.583s\n",
    "user    0m1.445s\n",
    "sys     0m0.136s\n",
    "\n",
    "\n",
    "from the following:\n",
    "https://stackoverflow.com/questions/22258491/read-a-small-random-sample-from-a-big-csv-file-into-a-python-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-09 - Citi Bike trip data.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvlist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on loop 1 with number of features being 15\n",
      "Now on loop 2 with number of features being 15\n",
      "Now on loop 3 with number of features being 15\n",
      "Now on loop 4 with number of features being 15\n",
      "Now on loop 5 with number of features being 15\n",
      "Now on loop 6 with number of features being 15\n",
      "Now on loop 7 with number of features being 15\n",
      "Now on loop 8 with number of features being 15\n",
      "Now on loop 9 with number of features being 15\n",
      "Now on loop 10 with number of features being 15\n",
      "Now on loop 11 with number of features being 15\n",
      "Now on loop 12 with number of features being 15\n",
      "Now on loop 13 with number of features being 15\n",
      "Now on loop 14 with number of features being 15\n",
      "Now on loop 15 with number of features being 15\n",
      "Now on loop 16 with number of features being 15\n",
      "Now on loop 17 with number of features being 15\n",
      "Now on loop 18 with number of features being 15\n",
      "Now on loop 19 with number of features being 15\n",
      "Now on loop 20 with number of features being 15\n",
      "Now on loop 21 with number of features being 15\n",
      "Now on loop 22 with number of features being 15\n",
      "Now on loop 23 with number of features being 15\n",
      "Now on loop 24 with number of features being 15\n",
      "Now on loop 25 with number of features being 15\n",
      "Now on loop 26 with number of features being 15\n",
      "Now on loop 27 with number of features being 15\n",
      "Now on loop 28 with number of features being 15\n",
      "Now on loop 29 with number of features being 15\n",
      "Now on loop 30 with number of features being 15\n",
      "Now on loop 31 with number of features being 15\n",
      "Now on loop 32 with number of features being 15\n",
      "Now on loop 33 with number of features being 16\n",
      "Now on loop 34 with number of features being 15\n",
      "Now on loop 35 with number of features being 15\n",
      "Now on loop 36 with number of features being 15\n",
      "Now on loop 37 with number of features being 15\n",
      "Now on loop 38 with number of features being 15\n",
      "Now on loop 39 with number of features being 15\n",
      "Now on loop 40 with number of features being 15\n",
      "Now on loop 41 with number of features being 15\n",
      "Now on loop 42 with number of features being 15\n",
      "Now on loop 43 with number of features being 15\n",
      "Now on loop 44 with number of features being 15\n",
      "Now on loop 45 with number of features being 15\n",
      "Now on loop 46 with number of features being 15\n",
      "Now on loop 47 with number of features being 15\n",
      "Now on loop 48 with number of features being 15\n",
      "Now on loop 49 with number of features being 15\n",
      "Now on loop 50 with number of features being 15\n",
      "Now on loop 51 with number of features being 15\n",
      "Now on loop 52 with number of features being 15\n",
      "Now on loop 53 with number of features being 15\n",
      "Now on loop 54 with number of features being 15\n",
      "Now on loop 55 with number of features being 15\n",
      "Now on loop 56 with number of features being 15\n",
      "Now on loop 57 with number of features being 15\n",
      "Now on loop 58 with number of features being 15\n",
      "Now on loop 59 with number of features being 15\n",
      "Now on loop 60 with number of features being 15\n",
      "Now on loop 61 with number of features being 15\n",
      "Now on loop 62 with number of features being 15\n",
      "Now on loop 63 with number of features being 15\n",
      "Now on loop 64 with number of features being 15\n",
      "Now on loop 65 with number of features being 15\n",
      "Now on loop 66 with number of features being 15\n",
      "Now on loop 67 with number of features being 15\n",
      "Now on loop 68 with number of features being 15\n",
      "Now on loop 69 with number of features being 15\n",
      "Now on loop 70 with number of features being 15\n",
      "Now on loop 71 with number of features being 15\n",
      "Now on loop 72 with number of features being 15\n",
      "Now on loop 73 with number of features being 15\n",
      "Now on loop 74 with number of features being 15\n",
      "Now on loop 75 with number of features being 15\n",
      "Now on loop 76 with number of features being 15\n",
      "Now on loop 77 with number of features being 15\n",
      "Now on loop 78 with number of features being 15\n",
      "Now on loop 79 with number of features being 15\n",
      "Now on loop 80 with number of features being 15\n",
      "Now on loop 81 with number of features being 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "seed(0)\n",
    "my_dfs = []\n",
    "csvlist = [f for f in glob.glob(\"*.csv\")]\n",
    "i=1\n",
    "\n",
    "for csv in csvlist:\n",
    "    df_downsample = pd_read_downsample(csv, 0.05)\n",
    "    df_downsample.columns = map(str.lower, df_downsample.columns)\n",
    "    df_downsample.columns = df_downsample.columns.str.replace(\" \", \"\")\n",
    "    print('Now on loop', i, 'with number of features being', len(df_downsample.columns))\n",
    "#     print('-'*55)\n",
    "#     print('Feature names: ', df_downsample.columns)\n",
    "    my_dfs.append(df_downsample)\n",
    "    i = i + 1\n",
    "\n",
    "fin_dat = pd.concat(my_dfs, axis=0)\n",
    "fin_dat.to_csv('concat_file_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fin_dat = pd.read_csv('concat_file_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dat = fin_dat.reset_index(drop=True)\n",
    "fin_dat = fin_dat.drop(['Unnamed: 0', 'unnamed:0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4705843 entries, 0 to 4705842\n",
      "Data columns (total 15 columns):\n",
      "bikeid                   int64\n",
      "birthyear                object\n",
      "endstationid             float64\n",
      "endstationlatitude       float64\n",
      "endstationlongitude      float64\n",
      "endstationname           object\n",
      "gender                   int64\n",
      "startstationid           float64\n",
      "startstationlatitude     float64\n",
      "startstationlongitude    float64\n",
      "startstationname         object\n",
      "starttime                object\n",
      "stoptime                 object\n",
      "tripduration             int64\n",
      "usertype                 object\n",
      "dtypes: float64(6), int64(3), object(6)\n",
      "memory usage: 538.5+ MB\n"
     ]
    }
   ],
   "source": [
    "fin_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218 locations\n"
     ]
    }
   ],
   "source": [
    "print('%d locations'%fin_dat.startstationlatitude.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dat['starttime'] = pd.to_datetime(fin_dat.starttime)\n",
    "fin_dat['stoptime'] = pd.to_datetime(fin_dat.stoptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4705843, 15)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>endstationid</th>\n",
       "      <th>endstationlatitude</th>\n",
       "      <th>endstationlongitude</th>\n",
       "      <th>endstationname</th>\n",
       "      <th>gender</th>\n",
       "      <th>startstationid</th>\n",
       "      <th>startstationlatitude</th>\n",
       "      <th>startstationlongitude</th>\n",
       "      <th>startstationname</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>usertype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16852</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>40.732264</td>\n",
       "      <td>-73.998522</td>\n",
       "      <td>MacDougal St &amp; Washington Sq</td>\n",
       "      <td>1</td>\n",
       "      <td>312.0</td>\n",
       "      <td>40.722055</td>\n",
       "      <td>-73.989111</td>\n",
       "      <td>Allen St &amp; Stanton St</td>\n",
       "      <td>2017-09-01 00:04:15</td>\n",
       "      <td>2017-09-01 00:11:18</td>\n",
       "      <td>422</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27730</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>40.765265</td>\n",
       "      <td>-73.981923</td>\n",
       "      <td>Broadway &amp; W 56 St</td>\n",
       "      <td>1</td>\n",
       "      <td>478.0</td>\n",
       "      <td>40.760301</td>\n",
       "      <td>-73.998842</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>2017-09-01 00:06:19</td>\n",
       "      <td>2017-09-01 00:17:09</td>\n",
       "      <td>650</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28032</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>40.688070</td>\n",
       "      <td>-73.984106</td>\n",
       "      <td>Bond St &amp; Schermerhorn St</td>\n",
       "      <td>1</td>\n",
       "      <td>237.0</td>\n",
       "      <td>40.730473</td>\n",
       "      <td>-73.986724</td>\n",
       "      <td>E 11 St &amp; 2 Ave</td>\n",
       "      <td>2017-09-01 00:07:34</td>\n",
       "      <td>2017-09-01 00:29:49</td>\n",
       "      <td>1334</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15651</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>40.721463</td>\n",
       "      <td>-73.948009</td>\n",
       "      <td>Eckford St &amp; Engert Ave</td>\n",
       "      <td>2</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>40.717746</td>\n",
       "      <td>-73.956001</td>\n",
       "      <td>N 8 St &amp; Driggs Ave</td>\n",
       "      <td>2017-09-01 00:10:49</td>\n",
       "      <td>2017-09-01 00:13:52</td>\n",
       "      <td>182</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17018</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>40.740343</td>\n",
       "      <td>-73.989551</td>\n",
       "      <td>Broadway &amp; E 22 St</td>\n",
       "      <td>0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>40.736245</td>\n",
       "      <td>-73.984738</td>\n",
       "      <td>E 19 St &amp; 3 Ave</td>\n",
       "      <td>2017-09-01 00:11:00</td>\n",
       "      <td>2017-09-01 00:15:39</td>\n",
       "      <td>278</td>\n",
       "      <td>Customer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bikeid  birthyear  endstationid  endstationlatitude  endstationlongitude  \\\n",
       "0   16852     1991.0         252.0           40.732264           -73.998522   \n",
       "1   27730     1983.0         468.0           40.765265           -73.981923   \n",
       "2   28032     1989.0         395.0           40.688070           -73.984106   \n",
       "3   15651     1989.0        3449.0           40.721463           -73.948009   \n",
       "4   17018     1900.0         402.0           40.740343           -73.989551   \n",
       "\n",
       "                 endstationname  gender  startstationid  startstationlatitude  \\\n",
       "0  MacDougal St & Washington Sq       1           312.0             40.722055   \n",
       "1            Broadway & W 56 St       1           478.0             40.760301   \n",
       "2     Bond St & Schermerhorn St       1           237.0             40.730473   \n",
       "3       Eckford St & Engert Ave       2          3090.0             40.717746   \n",
       "4            Broadway & E 22 St       0           325.0             40.736245   \n",
       "\n",
       "   startstationlongitude       startstationname           starttime  \\\n",
       "0             -73.989111  Allen St & Stanton St 2017-09-01 00:04:15   \n",
       "1             -73.998842       11 Ave & W 41 St 2017-09-01 00:06:19   \n",
       "2             -73.986724        E 11 St & 2 Ave 2017-09-01 00:07:34   \n",
       "3             -73.956001    N 8 St & Driggs Ave 2017-09-01 00:10:49   \n",
       "4             -73.984738        E 19 St & 3 Ave 2017-09-01 00:11:00   \n",
       "\n",
       "             stoptime  tripduration    usertype  \n",
       "0 2017-09-01 00:11:18           422  Subscriber  \n",
       "1 2017-09-01 00:17:09           650  Subscriber  \n",
       "2 2017-09-01 00:29:49          1334  Subscriber  \n",
       "3 2017-09-01 00:13:52           182  Subscriber  \n",
       "4 2017-09-01 00:15:39           278    Customer  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN in Dataframe:  258745\n",
      "Percent Missingness in Dataframe:  0.3665584820119725\n",
      "-------------------------------------------------------\n",
      "Percent Missingness by Columns:\n",
      "birthyear              5.356660\n",
      "usertype               0.055697\n",
      "endstationname         0.021505\n",
      "endstationid           0.021505\n",
      "endstationlongitude    0.018573\n",
      "endstationlatitude     0.018573\n",
      "startstationname       0.002933\n",
      "startstationid         0.002933\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#na survey of data after import\n",
    "colpercent(fin_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    4453767\n",
      "True      252076\n",
      "Name: birthyear, dtype: int64\n",
      "Index([  1888.0,   '1939', '1943.0',   1930.0, '1940.0',   '1935',     1887,\n",
      "         1910.0,   '1937',   '1936',     1899,   1912.0, '1938.0',   '1899',\n",
      "         '1934',     1924,   '1901',   1917.0,   1921.0,   1889.0,   1926.0,\n",
      "       '2000.0',   '2003', '1900.0',   '1933',     1918,     1886,   '1932',\n",
      "         1895.0,     1929,   '1922', '1939.0',   1931.0,   1893.0,   '1923',\n",
      "         1890.0,   '1888',     1896,     1919,     1907,   1894.0,   '1926',\n",
      "         '1910',   1928.0, '1935.0',     1909,   '1917',   '1921',     1913,\n",
      "           1911,   '1924', '1934.0', '1936.0', '1901.0',   1915.0, '1885.0',\n",
      "         1927.0, '1899.0',   '1907',   '1927',   '1930',   1922.0, '1922.0',\n",
      "         '1890',   '1929', '1932.0',   '1885', '1930.0',   '1913',   '1887',\n",
      "       '1937.0',   1916.0, '1910.0', '1921.0',   '1886',   1920.0,   '1918',\n",
      "         '1931',   '1896', '1926.0', '2001.0',   '1912',   '1894', '1933.0',\n",
      "           1897,   '1920',   '1909',   '1889',   1857.0, '1931.0',   '1895',\n",
      "       '1917.0', '1927.0',   1925.0, '1918.0',     1905, '1912.0', '1894.0'],\n",
      "      dtype='object')\n",
      "imputation complete\n"
     ]
    }
   ],
   "source": [
    "#birthyear column na handling and imputation\n",
    "\n",
    "#the number of na versus not na\n",
    "print(fin_dat.birthyear.isnull().value_counts())\n",
    "\n",
    "#this indicates that some of the years are cast as floats while others are strings\n",
    "print(fin_dat.birthyear[fin_dat.birthyear.notnull()].value_counts()[200:].index)\n",
    "\n",
    "#data is inconsistent in some na's being whitespace and others being actual na's, so replace for consistency\n",
    "fin_dat.birthyear = fin_dat.birthyear.replace('\\\\N', np.nan)\n",
    "fin_dat.birthyear.fillna(1900.0, inplace=True)\n",
    "fin_dat.birthyear = fin_dat.birthyear[fin_dat.birthyear.notnull()].astype('float16')\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900. 1912. 1885. 1901. 1894. 1893. 1917. 1910. 1888. 1895. 1899. 1886.\n",
      " 1896. 1918. 1887. 1907. 1913. 1915. 1916. 1889. 1890. 1911. 1897. 1919.\n",
      " 1909. 1857. 1905.]\n",
      "imputation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#birthyear column imputation for implausibly elderly\n",
    "\n",
    "#these ages seem implausible (Citibike starting in 2013 would put the most elderly rider at 94), \n",
    "#so we replace them with 1900.0\n",
    "birth_index = fin_dat.birthyear[fin_dat.birthyear.sort_values(ascending=False)<1920.0].index\n",
    "print(fin_dat.birthyear[birth_index].unique())\n",
    "fin_dat.birthyear[birth_index] = fin_dat.birthyear[birth_index].replace(list(fin_dat.birthyear[birth_index].unique()), 1900.0)\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation complete\n"
     ]
    }
   ],
   "source": [
    "#usertype column na handling and imputation\n",
    "\n",
    "#alternative is to look into proportional imputation by class\n",
    "fin_dat.usertype.fillna('Unknown', inplace=True)\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  95006,   97403,   98193,   98971,   99583,   99592,  100431,\n",
      "             101258,  101935,  105703,\n",
      "            ...\n",
      "            4117249, 4121669, 4122217, 4122980, 4123457, 4126173, 4147953,\n",
      "            4158820, 4159321, 4164415],\n",
      "           dtype='int64', length=1012)\n",
      "Int64Index([  95006,   97403,   98193,   98971,   99583,   99592,  100431,\n",
      "             101258,  101935,  105703,\n",
      "            ...\n",
      "            4117249, 4121669, 4122217, 4122980, 4123457, 4126173, 4147953,\n",
      "            4158820, 4159321, 4164415],\n",
      "           dtype='int64', length=1012)\n",
      "Int64Index([1952760, 1952776, 1952788, 1952860, 1952863, 1952865, 1952879,\n",
      "            1952905, 1952908, 1952923,\n",
      "            ...\n",
      "            3465103, 3465133, 3465146, 3465216, 3465355, 3465357, 3465389,\n",
      "            3465396, 3465430, 3465448],\n",
      "           dtype='int64', length=874)\n",
      "Int64Index([1952760, 1952776, 1952788, 1952860, 1952863, 1952865, 1952879,\n",
      "            1952905, 1952908, 1952923,\n",
      "            ...\n",
      "            3465103, 3465133, 3465146, 3465216, 3465355, 3465357, 3465389,\n",
      "            3465396, 3465430, 3465448],\n",
      "           dtype='int64', length=874)\n",
      "imputation complete\n"
     ]
    }
   ],
   "source": [
    "#endstation na handling and imputation\n",
    "\n",
    "#the missing station names, id, lat and long indexes coincide, so these observations cannot be used for route analysis and should be removed\n",
    "print(fin_dat.endstationname[fin_dat.endstationname.isnull()].index)\n",
    "print(fin_dat.endstationid[fin_dat.endstationid.isnull()].index)\n",
    "print(fin_dat.endstationlatitude[fin_dat.endstationlatitude.isnull()].index)\n",
    "print(fin_dat.endstationlongitude[fin_dat.endstationlongitude.isnull()].index)\n",
    "\n",
    "fin_dat.drop(fin_dat[fin_dat.endstationid.isnull()].index, axis=0, inplace=True)\n",
    "\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "Int64Index([], dtype='int64')\n",
      "imputation complete\n"
     ]
    }
   ],
   "source": [
    "#startstation na handling and imputation\n",
    "\n",
    "#the missing station names and id indexes coincide, so these observations cannot be used for route analysis and should be removed\n",
    "print(fin_dat.startstationname[fin_dat.startstationname.isnull()].index)\n",
    "print(fin_dat.startstationid[fin_dat.startstationid.isnull()].index)\n",
    "\n",
    "fin_dat.drop(fin_dat[fin_dat.startstationid.isnull()].index, axis=0, inplace=True)\n",
    "\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that imputations and removals are completed, we need to reset index\n",
    "\n",
    "fin_dat = fin_dat.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN in Dataframe:  0\n",
      "Percent Missingness in Dataframe:  0.0\n",
      "-------------------------------------------------------\n",
      "Percent Missingness by Columns:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "#to verify all nas are gone\n",
    "colpercent(fin_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Notes:\n",
    "1. Need to convert starttime and stoptime to datetime format or equivalent. This can be done automatically while reading in  with the parse_dates method, but would be faster to do selectively after downsampling. The former may be unavoidable if the groupby needs to be done by month though\n",
    "2. Implement downsampling, ideally read in directly as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978590   -3434.0\n",
      "3589117   -3226.0\n",
      "2804411   -3170.0\n",
      "2804412   -3129.0\n",
      "3589116   -2301.0\n",
      "3589115   -1951.0\n",
      "3589118    -959.0\n",
      "3589112    -168.0\n",
      "2520413      60.0\n",
      "849863       60.0\n",
      "3733825      60.0\n",
      "3738704      60.0\n",
      "850119       60.0\n",
      "2348093      60.0\n",
      "4080806      60.0\n",
      "868634       60.0\n",
      "3738879      60.0\n",
      "3817906      60.0\n",
      "891442       60.0\n",
      "1756041      60.0\n",
      "dtype: float64\n",
      "2019-08-03 15:06:41.843000\n",
      "2019-08-03 15:26:49.096000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#timeDelta method for computing time of travel\n",
    "print((fin_dat.stoptime - fin_dat.starttime).dt.total_seconds().sort_values(ascending=True)[:20])\n",
    "\n",
    "#index values of concern:\n",
    "# 1978590   \n",
    "# 3589117   \n",
    "# 2804411  \n",
    "# 2804412   \n",
    "# 3589116  \n",
    "# 3589115   \n",
    "# 3589118 \n",
    "# 3589112 \n",
    "\n",
    "#for more information if method is insufficiently time-efficient\n",
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/timedeltas.html\n",
    "#https://stackoverflow.com/questions/22923775/calculate-pandas-dataframe-time-difference-between-two-columns-in-hours-and-minu\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.total_seconds.html\n",
    "\n",
    "#error in starttime and stoptime labeling, need to reverse what is starttime and what is stoptime\n",
    "#we will assume here that all station labels are correct, simply start and stoptimes were inserted incorrectly\n",
    "\n",
    "#fin_dat.iloc[551566,:].starttime, fin_dat.iloc[551566,:].stoptime = fin_dat.iloc[551566,:].stoptime, fin_dat.iloc[551566,:].starttime\n",
    "start = fin_dat.iloc[551566,:].starttime\n",
    "stop = fin_dat.iloc[551566,:].stoptime\n",
    "\n",
    "print(start)\n",
    "print(stop)\n",
    "\n",
    "# fin_dat.iloc[551566,:].starttime = fin_dat.iloc[551566,:].starttime.replace(minute=stop.minute, second=stop.second)\n",
    "# fin_dat.iloc[551566,:].stoptime = fin_dat.iloc[551566,:].stoptime.replace(minute=start.minute, second=start.second)\n",
    "\n",
    "fin_dat.iloc[551566,:].starttime = fin_dat.iloc[551566,:].starttime.replace(minute=stop.minute, second=stop.second)\n",
    "#fin_dat.iloc[551566,:].stoptime.replace(minute=stop.minute, second=stop.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392818\n",
      "---------------------------------------------\n",
      "4461838\n",
      "---------------------------------------------\n",
      "391554     3600.0\n",
      "391555     3600.0\n",
      "770833     3599.0\n",
      "776863     3600.0\n",
      "795517     3600.0\n",
      "            ...  \n",
      "4112921      21.0\n",
      "4112922      19.0\n",
      "4112923       4.0\n",
      "4583493    3600.0\n",
      "4631912    3599.0\n",
      "Length: 41787, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "diff=fin_dat.tripduration-(fin_dat.stoptime - fin_dat.starttime).dt.total_seconds()\n",
    "#this indicates that only around 1/4 of the observations are in agreement\n",
    "print(len(diff[diff==0]))\n",
    "print('-'*45)\n",
    "#a large majority of the observations are either in agreement or the differences are due to rounding error\n",
    "#these are sufficiently close that we can for our purposes just keep the values we already have in tripduration\n",
    "print(len(diff[abs(diff)<=1]))\n",
    "print('-'*45)\n",
    "#only around 42000 observations have actual errors\n",
    "print(diff[abs(diff>1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: tripduration, dtype: int64)\n",
      "---------------------------------------------\n",
      "391554        4451\n",
      "391555        4178\n",
      "770833     1309033\n",
      "776863     1199464\n",
      "795517       49206\n",
      "            ...   \n",
      "4112921        741\n",
      "4112922        259\n",
      "4112923        304\n",
      "4583493    8461569\n",
      "4631912    2518958\n",
      "Name: tripduration, Length: 41787, dtype: int64\n",
      "---------------------------------------------\n",
      "391554        8051.0\n",
      "391555        7778.0\n",
      "770833     1312632.0\n",
      "776863     1203064.0\n",
      "795517       52806.0\n",
      "             ...    \n",
      "4112921        762.0\n",
      "4112922        278.0\n",
      "4112923        308.0\n",
      "4583493    8465169.0\n",
      "4631912    2522557.0\n",
      "Length: 41787, dtype: float64\n",
      "391554        4451\n",
      "391555        4178\n",
      "770833     1309033\n",
      "776863     1199464\n",
      "795517       49206\n",
      "            ...   \n",
      "4112921        741\n",
      "4112922        259\n",
      "4112923        304\n",
      "4583493    8461569\n",
      "4631912    2518958\n",
      "Name: tripduration, Length: 41787, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "error_index = diff[abs(diff>1)].index\n",
    "#there are no negative values here\n",
    "print(fin_dat.tripduration[error_index][fin_dat.tripduration[error_index]<0])\n",
    "print('-'*45)\n",
    "\n",
    "#confirming the sum is as it should be\n",
    "print(fin_dat.iloc[error_index, -2])\n",
    "print('-'*45)\n",
    "print(fin_dat.tripduration[error_index] + diff[abs(diff>1)])\n",
    "print(fin_dat.tripduration[error_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#made correction to update tripduration values with error\n",
    "fin_dat.tripduration[error_index] = fin_dat.tripduration[error_index] + diff[abs(diff>1)]\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_feat = ['birthyear','starttime', 'stoptime']\n",
    "num_nom_feat = ['bikeid','endstationid','startstationid','gender']\n",
    "cat_nom_feat = ['endstationname','startstationname','usertype']\n",
    "nom_feat = num_nom_feat + cat_nom_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_to_int = ['startstationid','endstationid','tripduration', 'bikeid', 'gender']\n",
    "\n",
    "#change to int16 to reduce memory\n",
    "fin_dat.birthyear = fin_dat.birthyear.astype('float16').astype('int16')\n",
    "fin_dat[float_to_int] = fin_dat[float_to_int].apply(lambda x: x.astype('int16'))\n",
    "\n",
    "#and for nominal features\n",
    "fin_dat[cat_nom_feat] = fin_dat[cat_nom_feat].apply(lambda x: x.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>endstationid</th>\n",
       "      <th>endstationlatitude</th>\n",
       "      <th>endstationlongitude</th>\n",
       "      <th>endstationname</th>\n",
       "      <th>gender</th>\n",
       "      <th>startstationid</th>\n",
       "      <th>startstationlatitude</th>\n",
       "      <th>startstationlongitude</th>\n",
       "      <th>startstationname</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>usertype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4455178</td>\n",
       "      <td>15443</td>\n",
       "      <td>1900</td>\n",
       "      <td>173</td>\n",
       "      <td>40.760683</td>\n",
       "      <td>-73.984527</td>\n",
       "      <td>Broadway &amp; W 49 St</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>40.765909</td>\n",
       "      <td>-73.976342</td>\n",
       "      <td>Central Park S &amp; 6 Ave</td>\n",
       "      <td>2016-05-28 19:22:04</td>\n",
       "      <td>2016-05-28 19:41:40</td>\n",
       "      <td>1176</td>\n",
       "      <td>Customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2022803</td>\n",
       "      <td>18488</td>\n",
       "      <td>1964</td>\n",
       "      <td>168</td>\n",
       "      <td>40.739713</td>\n",
       "      <td>-73.994564</td>\n",
       "      <td>W 18 St &amp; 6 Ave</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>40.739445</td>\n",
       "      <td>-73.976806</td>\n",
       "      <td>E 27 St &amp; 1 Ave</td>\n",
       "      <td>2017-11-27 12:14:56</td>\n",
       "      <td>2017-11-27 12:25:43</td>\n",
       "      <td>647</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2051817</td>\n",
       "      <td>20860</td>\n",
       "      <td>1949</td>\n",
       "      <td>168</td>\n",
       "      <td>40.739713</td>\n",
       "      <td>-73.994564</td>\n",
       "      <td>W 18 St &amp; 6 Ave</td>\n",
       "      <td>1</td>\n",
       "      <td>442</td>\n",
       "      <td>40.746647</td>\n",
       "      <td>-73.993915</td>\n",
       "      <td>W 27 St &amp; 7 Ave</td>\n",
       "      <td>2016-12-13 06:53:22</td>\n",
       "      <td>2016-12-13 06:58:47</td>\n",
       "      <td>324</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3007606</td>\n",
       "      <td>16202</td>\n",
       "      <td>1983</td>\n",
       "      <td>365</td>\n",
       "      <td>40.682232</td>\n",
       "      <td>-73.961458</td>\n",
       "      <td>Fulton St &amp; Grand Ave</td>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>40.689888</td>\n",
       "      <td>-73.981013</td>\n",
       "      <td>DeKalb Ave &amp; Hudson Ave</td>\n",
       "      <td>2014-12-25 00:51:39</td>\n",
       "      <td>2014-12-25 01:01:08</td>\n",
       "      <td>569</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2022782</td>\n",
       "      <td>17872</td>\n",
       "      <td>1960</td>\n",
       "      <td>468</td>\n",
       "      <td>40.765265</td>\n",
       "      <td>-73.981923</td>\n",
       "      <td>Broadway &amp; W 56 St</td>\n",
       "      <td>1</td>\n",
       "      <td>3172</td>\n",
       "      <td>40.778567</td>\n",
       "      <td>-73.977550</td>\n",
       "      <td>W 74 St &amp; Columbus Ave</td>\n",
       "      <td>2017-11-27 11:59:33</td>\n",
       "      <td>2017-11-27 12:10:15</td>\n",
       "      <td>641</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2035624</td>\n",
       "      <td>14551</td>\n",
       "      <td>1989</td>\n",
       "      <td>236</td>\n",
       "      <td>40.728419</td>\n",
       "      <td>-73.987140</td>\n",
       "      <td>St Marks Pl &amp; 2 Ave</td>\n",
       "      <td>2</td>\n",
       "      <td>472</td>\n",
       "      <td>40.745712</td>\n",
       "      <td>-73.981948</td>\n",
       "      <td>E 32 St &amp; Park Ave</td>\n",
       "      <td>2016-12-02 16:47:43</td>\n",
       "      <td>2016-12-02 16:58:21</td>\n",
       "      <td>637</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3539070</td>\n",
       "      <td>28283</td>\n",
       "      <td>1973</td>\n",
       "      <td>297</td>\n",
       "      <td>40.734232</td>\n",
       "      <td>-73.986923</td>\n",
       "      <td>E 15 St &amp; 3 Ave</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>40.735877</td>\n",
       "      <td>-73.982050</td>\n",
       "      <td>E 20 St &amp; 2 Ave</td>\n",
       "      <td>2017-12-05 07:31:44</td>\n",
       "      <td>2017-12-05 07:36:28</td>\n",
       "      <td>283</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956266</td>\n",
       "      <td>21403</td>\n",
       "      <td>1992</td>\n",
       "      <td>448</td>\n",
       "      <td>40.756604</td>\n",
       "      <td>-73.997901</td>\n",
       "      <td>W 37 St &amp; 10 Ave</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "      <td>40.751551</td>\n",
       "      <td>-73.993934</td>\n",
       "      <td>8 Ave &amp; W 33 St</td>\n",
       "      <td>2016-10-11 18:21:17</td>\n",
       "      <td>2016-10-11 18:25:29</td>\n",
       "      <td>252</td>\n",
       "      <td>Subscriber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bikeid  birthyear  endstationid  endstationlatitude  \\\n",
       "4455178   15443       1900           173           40.760683   \n",
       "2022803   18488       1964           168           40.739713   \n",
       "2051817   20860       1949           168           40.739713   \n",
       "3007606   16202       1983           365           40.682232   \n",
       "2022782   17872       1960           468           40.765265   \n",
       "2035624   14551       1989           236           40.728419   \n",
       "3539070   28283       1973           297           40.734232   \n",
       "956266    21403       1992           448           40.756604   \n",
       "\n",
       "         endstationlongitude         endstationname  gender  startstationid  \\\n",
       "4455178           -73.984527     Broadway & W 49 St       0            2006   \n",
       "2022803           -73.994564        W 18 St & 6 Ave       1            2012   \n",
       "2051817           -73.994564        W 18 St & 6 Ave       1             442   \n",
       "3007606           -73.961458  Fulton St & Grand Ave       2             324   \n",
       "2022782           -73.981923     Broadway & W 56 St       1            3172   \n",
       "2035624           -73.987140    St Marks Pl & 2 Ave       2             472   \n",
       "3539070           -73.986923        E 15 St & 3 Ave       1             461   \n",
       "956266            -73.997901       W 37 St & 10 Ave       1             490   \n",
       "\n",
       "         startstationlatitude  startstationlongitude         startstationname  \\\n",
       "4455178             40.765909             -73.976342   Central Park S & 6 Ave   \n",
       "2022803             40.739445             -73.976806          E 27 St & 1 Ave   \n",
       "2051817             40.746647             -73.993915          W 27 St & 7 Ave   \n",
       "3007606             40.689888             -73.981013  DeKalb Ave & Hudson Ave   \n",
       "2022782             40.778567             -73.977550   W 74 St & Columbus Ave   \n",
       "2035624             40.745712             -73.981948       E 32 St & Park Ave   \n",
       "3539070             40.735877             -73.982050          E 20 St & 2 Ave   \n",
       "956266              40.751551             -73.993934          8 Ave & W 33 St   \n",
       "\n",
       "                  starttime            stoptime  tripduration    usertype  \n",
       "4455178 2016-05-28 19:22:04 2016-05-28 19:41:40          1176    Customer  \n",
       "2022803 2017-11-27 12:14:56 2017-11-27 12:25:43           647  Subscriber  \n",
       "2051817 2016-12-13 06:53:22 2016-12-13 06:58:47           324  Subscriber  \n",
       "3007606 2014-12-25 00:51:39 2014-12-25 01:01:08           569  Subscriber  \n",
       "2022782 2017-11-27 11:59:33 2017-11-27 12:10:15           641  Subscriber  \n",
       "2035624 2016-12-02 16:47:43 2016-12-02 16:58:21           637  Subscriber  \n",
       "3539070 2017-12-05 07:31:44 2017-12-05 07:36:28           283  Subscriber  \n",
       "956266  2016-10-11 18:21:17 2016-10-11 18:25:29           252  Subscriber  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#location of observations where lat and/or long don't make any sense\n",
    "observe = [4455178, 2022803, 2051817, 3007606, 2022782, 2035624, 3539070, 956266]\n",
    "\n",
    "#the entries have been left as zeroes\n",
    "fin_dat.iloc[observe,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this fixes most\n",
    "fin_dat.loc[fin_dat['endstationlatitude'] == 0, 'endstationlatitude'] = 40.75\n",
    "fin_dat.loc[fin_dat['endstationlongitude'] == 0, 'endstationlongitude'] = -74.0\n",
    "fin_dat.loc[fin_dat['startstationlongitude']==0, 'startstationlongitude'] = -74.0\n",
    "fin_dat.loc[fin_dat['startstationlatitude'] == 0, 'startstationlatitude'] = 40.75\n",
    "\n",
    "#faulty for startstationname (WS, don't use), so we drop it\n",
    "fin_dat.drop(4455178, axis=0, inplace=True)\n",
    "fin_dat.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    4105003\n",
      "True      599827\n",
      "Name: bikeid, dtype: int64\n",
      "7580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([-31752, -31231, -31563, -31261, -31445, -31380, -31730, -31646,\n",
       "            -32656, -31410,\n",
       "            ...\n",
       "            -27903, -23512, -25922, -28384, -26932, -27589, -27584, -31809,\n",
       "            -27111, -28929],\n",
       "           dtype='int64', length=7580)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negative bikeids is an issue?\n",
    "print((fin_dat.bikeid<0).value_counts())\n",
    "print(len(fin_dat.loc[fin_dat.bikeid<0].bikeid.value_counts().index))\n",
    "fin_dat.loc[fin_dat.bikeid<0].bikeid.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dat.drop(fin_dat.loc[fin_dat.bikeid <0].index, inplace=True)\n",
    "fin_dat.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are some addition values that may need removal\n",
    "#Hs Don't Use, WS Don't Use, NYCBS Test\n",
    "fin_dat.drop(fin_dat[fin_dat.startstationname==\"Hs Don't Use\"].index, axis=0, inplace=True)\n",
    "fin_dat.drop(fin_dat[fin_dat.startstationname==\"WS Don't Use\"].index, axis=0, inplace=True)\n",
    "fin_dat.drop(fin_dat[fin_dat.startstationname==\"NYCBS Test\"].index, axis=0, inplace=True)\n",
    "fin_dat.drop(fin_dat[fin_dat.endstationname==\"NYCBS Test\"].index, axis=0, inplace=True)\n",
    "fin_dat.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4017571\n",
      "4104983\n",
      "imputation complete\n"
     ]
    }
   ],
   "source": [
    "#print(fin_dat.tripduration.sort_values(ascending=True)[:10000])\n",
    "#issue with riders getting bike and then shortly after returning them to same dock station without real use.\n",
    "#print(fin_dat.iloc[663912,:])\n",
    "\n",
    "#remove observations where cyclists return bike to same dock\n",
    "#fin_dat.drop(fin_dat.iloc[fin_dat.startstationid == fin_dat.endstationid], axis=1)\n",
    "fin_dat.loc[fin_dat.startstationid == fin_dat.endstationid, :].index\n",
    "print(len(fin_dat.drop(fin_dat.loc[fin_dat.startstationid == fin_dat.endstationid, :].index, axis=0)))\n",
    "print(len(fin_dat))\n",
    "\n",
    "#how do I determine which subset of these rides are not actual rides (rider misuse) or actual rides\n",
    "#i.e., cyclists returning to the same location they started after riding for a time\n",
    "fin_dat.loc[fin_dat.startstationid == fin_dat.endstationid, :].tripduration.sort_values()[:500]\n",
    "\n",
    "#we will just cut them all to be conservative\n",
    "fin_dat.drop(fin_dat.loc[fin_dat.startstationid == fin_dat.endstationid, :].index, axis=0, inplace=True)\n",
    "print('imputation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dat = fin_dat.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4015035 entries, 0 to 4104982\n",
      "Data columns (total 15 columns):\n",
      "bikeid                   int16\n",
      "birthyear                int16\n",
      "endstationid             int16\n",
      "endstationlatitude       float64\n",
      "endstationlongitude      float64\n",
      "endstationname           category\n",
      "gender                   int16\n",
      "startstationid           int16\n",
      "startstationlatitude     float64\n",
      "startstationlongitude    float64\n",
      "startstationname         category\n",
      "starttime                datetime64[ns]\n",
      "stoptime                 datetime64[ns]\n",
      "tripduration             int16\n",
      "usertype                 category\n",
      "dtypes: category(3), datetime64[ns](2), float64(4), int16(6)\n",
      "memory usage: 279.6 MB\n"
     ]
    }
   ],
   "source": [
    "fin_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4015035, 15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183 locations\n"
     ]
    }
   ],
   "source": [
    "print('%d locations'%fin_dat.startstationlatitude.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dat.to_csv('citibike_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
